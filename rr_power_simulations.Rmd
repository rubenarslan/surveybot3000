---
title: "Precision simulations"
author: "Ruben Arslan"
date: "2023-11-07"
output: html_document
---


The following precision simulations all follow the same structure.
 - We randomly redraw from our holdout data to get realistic distributions
    of estimates.
 - We repeat this random drawing process many times.
 - We adjust for sampling error/the standard error of the empirical estimate.
 - The target quantity is the standard error of the accuracy with which the
   synthetic estimates predicts the empirical estimates.

 We begin with item correlations, then reliabilities, then scale correlations.

```{r}
library(tidyverse)

number_of_items <- 175
number_of_scales <- 40
combinations_items <- choose(number_of_items, 2)
combinations_scales <- choose(number_of_scales, 2)
```


## Precision simulation for synthetic inter-item correlations
```{r}
holdout <- arrow::read_feather("ignore.data-holdout-set-item-similarity-20230710-164559")
llm_holdout_meta <- arrow::read_feather("ignore.llmdata-holdout-set-item-similarity-20230710-164559.feather") %>% select(DatasetId, ItemStemId, Variable) %>%
  left_join(arrow::read_feather("ignore.item-similarity-20230710-164559.raw.osf-bainbridge-2021-s2-0.mapping.feather"), by = c("Variable" = 'variable')) %>%
  rename(scale_0 = scale0,
         scale_1 = scale1)

holdout_llm <- holdout %>%
  select(ItemStemIdA, ItemStemIdB, Pearson, CosineSimilarity) %>%
  left_join(llm_holdout_meta %>% select(ItemStemIdA = ItemStemId, VariableA = Variable, InstrumentA = instrument, ScaleA = scale_0, SubscaleA = scale_1)) %>%
  left_join(llm_holdout_meta %>% select(ItemStemIdB = ItemStemId, VariableB = Variable, InstrumentB = instrument, ScaleB = scale_0, SubscaleB = scale_1))

sim_results <- tibble()
library(lavaan)

for(i in 1:500) {
  items <- holdout %>% select(ItemStemIdA) %>% distinct() %>% sample_n(175) %>% pull(ItemStemIdA)

  subset <- holdout %>% filter(ItemStemIdA %in% items, ItemStemIdB %in% items)

  N <- 400
  subset <- subset %>% mutate(se = (1 - Pearson^2)/sqrt(N - 2))
  se2 <- mean(subset$se^2)

  r <- broom::tidy(cor.test(subset$Pearson, subset$CosineSimilarity))
  (r$conf.high - r$conf.low)/2

  model <- paste0('
    # Latent variables
    PearsonLatent =~ 1*Pearson

    # Fixing error variances based on known standard errors
    Pearson ~~ ',se2,'*Pearson

    # Relationship between latent variables
    PearsonLatent ~~ CosineSimilarity
  ')

  fit <- sem(model, data = subset)

  sim_results <- bind_rows(sim_results,
    standardizedsolution(fit) %>% filter(lhs == "PearsonLatent", rhs ==  "CosineSimilarity")
  )
}
sim_results %>% summarise(mean(est.std), sqrt(mean(se^2)), max(se))
```


## Precision simulation for synthetic reliabilities
```{r}
cors_llm <- holdout_llm %>%
  select(x = VariableA, y = VariableB, r = CosineSimilarity) %>%
  as.data.frame() |>
  igraph::graph_from_data_frame(directed = FALSE) |>
  igraph::as_adjacency_matrix(attr = "r", sparse = FALSE)
diag(cors_llm) <- 1

cors_real <- holdout_llm %>%
  select(x = VariableA, y = VariableB, r = Pearson) %>%
  as.data.frame() |>
  igraph::graph_from_data_frame(directed = FALSE) |>
  igraph::as_adjacency_matrix(attr = "r", sparse = FALSE)
diag(cors_real) <- 1

subscales <- llm_holdout_meta %>%
  select(instrument, scale_0, scale_1, Variable, ItemStemId) %>%
  distinct() %>%
  mutate(instrument = coalesce(str_c(str_trim(instrument), "_"), ""),
         scale_0 = coalesce(str_c(str_trim(scale_0), "_"), ""),
         scale_1 = coalesce(str_trim(scale_1), ""),
         scale = str_replace_all(paste0(instrument, scale_0, scale_1), "[^a-zA-Z_0-9]", "_")
  )
n_distinct(subscales$scale)

scales <- llm_holdout_meta %>%
  select(instrument, scale_0, scale_1, Variable, ItemStemId) %>%
  distinct() %>%
  mutate(instrument = coalesce(str_c(str_trim(instrument), "_"), ""),
         scale_0 = coalesce(str_c(str_trim(scale_0), "_"), ""),
         scale_1 = "",
         scale = str_replace_all(paste0(instrument, scale_0, scale_1), "[^a-zA-Z_0-9]", "_")
  )

scales <- bind_rows(scales, subscales) %>% distinct() %>% filter(scale != "")
n_distinct(scales$scale)

scales <- scales %>%
  group_by(scale) %>%
  summarise(
    items = list(Variable),
    number_of_items = n_distinct(Variable),
    lvn = paste(first(scale), " =~ ", paste(Variable, collapse = " + "))) %>%
  drop_na()

random_scales <- list()
for(i in 1:1000) {
  n_items <- rpois(1, 10)
  n_items <- if_else(n_items < 3, 3, n_items)
  random_scales[[i]] <- llm_holdout_meta %>%
    sample_n(n_items) %>%
    mutate(scale = paste0("random", i)) %>%
    group_by(scale) %>%
    summarise(
      items = list(Variable),
      number_of_items = n_distinct(Variable),
      lvn = paste(first(scale), " =~ ", paste(Variable, collapse = " + "))) %>%
    drop_na()
}

random_scales <- bind_rows(random_scales)
scales <- bind_rows(scales, random_scales)
n_distinct(scales$scale)

find_reverse_items_by_first_item <- function(rs) {
  # negatively correlated with first item
  items <- rs[-1, 1]
  reverse_keyed_items <- names(items)[which(items < 0)]
  reverse_keyed_items
}

reverse_items <- function(rs, reverse_keyed_items) {
  # Reverse the correlations for the reverse-keyed items
  for (item in reverse_keyed_items) {
    # Get the index of the reverse-keyed item
    item_index <- which(rownames(rs) == item)

    # Reverse the correlations
    rs[item_index, ] <- rs[item_index, ] * -1
    rs[, item_index] <- rs[, item_index] * -1

    # Since the diagonal is the correlation of the item with itself, set it back to 1
    rs[item_index, item_index] <- 1
  }
  rs
}

scales <- scales %>% filter(number_of_items >= 3)

scales <- scales %>%
  rowwise() %>%
  mutate(r_real = list(cors_real[items, items]),
         r_llm = list(cors_llm[items, items])) %>%
  mutate(reverse_items = list(find_reverse_items_by_first_item(r_real)),
         r_real_rev = list(reverse_items(r_real, reverse_items)),
         r_llm_rev = list(reverse_items(r_llm, reverse_items))) %>%
  mutate(
    rel_real = list(psych::alpha(r_real_rev, keys = F, n.obs = 400)$feldt)) %>%
  mutate(
    rel_llm = list(psych::alpha(r_llm_rev, keys = F, n.obs = 400)$feldt)) %>%
  mutate(rel_real_alpha = rel_real$alpha$raw_alpha,
         rel_llm_alpha = rel_llm$alpha$raw_alpha) %>%
  mutate(
    alpha_se = mean(diff(unlist(psychometric::alpha.CI(rel_real_alpha, k = number_of_items, N = 400, level = 0.95))))
  )

qplot(scales$alpha_se)
qplot(scales$rel_real_alpha, scales$alpha_se)
qplot(scales$number_of_items, scales$alpha_se)
qplot(scales$rel_real_alpha, scales$alpha_se, color = scales$number_of_items)

realistic_scales <- scales %>% ungroup()

sim_results <- tibble()
for(i in 1:500) {
  picked_scales <- realistic_scales %>% filter(!str_detect(scale, "random")) %>% sample_n(number_of_scales)
  subset <-
    bind_rows(picked_scales,
              realistic_scales %>% filter(str_detect(scale, "random")) %>% sample_n(200)
  )

  se2 <- mean(subset$alpha_se^2)

  r <- broom::tidy(cor.test(subset$rel_real_alpha, subset$rel_llm_alpha))
  (r$conf.high - r$conf.low)/2

  model <- paste0('
    # Latent variables
    PearsonLatent =~ 1*rel_real_alpha

    # Fixing error variances based on known standard errors
    rel_real_alpha ~~ ',se2,'*rel_real_alpha

    # Relationship between latent variables
    PearsonLatent ~~ rel_llm_alpha
  ')

  fit <- sem(model, data = subset)

  sim_results <- bind_rows(sim_results,
                           standardizedsolution(fit) %>% filter(lhs == "PearsonLatent", rhs ==  "rel_llm_alpha")
  )
}
sim_results %>%
  summarise(mean(est.std), sqrt(mean(se^2, na.rm = T)),
            max(se))

scales %>% group_by(number_of_items) %>%
  summarise(cor(rel_real_alpha, rel_llm_alpha), n())
```


## Precision simulation for synthetic scale correlations
```{r}
predict_manifest_scores = function(human_data, machine_data, mapping_data) {
  human_cor = human_data %>%
    cor(use = "p")

  machine_cor = machine_data %>%
    cor(use = "p")

  mapping_data <- mapping_data %>%
    mutate(instrument = coalesce(str_c(str_trim(instrument), "_"), ""),
           scale0 = coalesce(str_c(str_trim(scale0), "_"), ""),
           scale1 = coalesce(str_trim(scale1), ""),
           scale = str_replace_all(paste0(instrument, scale0, scale1), "[^a-zA-Z_0-9]", "_")
    )


  scale_data = mapping_data %>%
    dplyr::group_by(scale) %>%
    dplyr::summarize(
      items = list(variable)
    ) %>%
    dplyr::rowwise() %>%
    dplyr::mutate(
      human_cor = list(human_cor[items, items]),
      reverse_keyed_items = list(find_reverse_items_by_first_item(human_cor)),
    ) %>%
    dplyr::select(-human_cor) %>%
    dplyr::ungroup()


  scale_pairs = combn(x = scale_data$scale, m = 2) %>%
    t()

  manifest_scores = tibble()

  calculate_row_means = function(data_, scale_data_) {
    data_ %>%
      dplyr::select(
        scale_data_$items %>%
          unlist() %>%
          dplyr::all_of()
      ) %>%
      dplyr::mutate_at(
        .vars = scale_data_$reverse_keyed_items %>%
          unlist(),
        .funs = function(x) max(., na.rm = TRUE) + 1 - x
      ) %>%
      rowMeans(na.rm = TRUE)
  }

  for (i in seq_len(nrow(scale_pairs))) {
    scale_a = scale_pairs[i, 1]
    scale_b = scale_pairs[i, 2]

    scale_data_a = scale_data %>%
      dplyr::filter(scale == scale_a)

    scale_data_b = scale_data %>%
      dplyr::filter(scale == scale_b)

    human_a = calculate_row_means(human_data, scale_data_a)
    human_b = calculate_row_means(human_data, scale_data_b)
    machine_a = calculate_row_means(machine_data, scale_data_a)
    machine_b = calculate_row_means(machine_data, scale_data_b)

    manifest_scores = manifest_scores %>%
      dplyr::bind_rows(
        tibble(
          scale_a = scale_a,
          scale_b = scale_b,
          human_cor = cor(human_a, human_b, use = "p"),
          machine_cor = cor(machine_a, machine_b, use = "p")
        )
      )
  }
  return(manifest_scores)
}


holdout_human_data = arrow::read_feather(
  file = "ignore.item-similarity-20230710-164559.raw.osf-bainbridge-2021-s2-0.human.feather")

# fine-tuned model
holdout_machine_data = arrow::read_feather(
  file = "ignore.item-similarity-20230710-164559.raw.osf-bainbridge-2021-s2-0.machine.feather")

holdout_mapping_data = arrow::read_feather(
  file = "ignore.item-similarity-20230710-164559.raw.osf-bainbridge-2021-s2-0.mapping.feather")

manifest_scores = predict_manifest_scores(holdout_human_data, holdout_machine_data, holdout_mapping_data)
n_distinct(manifest_scores$scale_a)

N <- 340
manifest_scores <- manifest_scores %>% mutate(se = (1 - human_cor^2)/sqrt(N - 2))
se2 <- mean(manifest_scores$se^2)

manifest_scores <- manifest_scores %>%
 left_join(scales, by = c("scale_a" = "scale")) %>%
 left_join(scales, by = c("scale_b" = "scale"))

manifest_scores %>%
  mutate(items = number_of_items.x + number_of_items.y) %>%
  group_by(items) %>%
  summarise(cor = cor(human_cor, machine_cor), n()) %>%
  ggplot(aes(items, cor)) + geom_point()


manifest_scores %>%
  filter(number_of_items.x > 4, number_of_items.y > 4) %>%
  summarise(cor = cor(human_cor, machine_cor), n())

r <- broom::tidy(cor.test(manifest_scores$human_cor, manifest_scores$machine_cor))

model <- paste0('
    # Latent variables
    PearsonLatent =~ 1*human_cor

    # Fixing error variances based on known standard errors
    human_cor ~~ ',se2,'*human_cor

    # Relationship between latent variables
    PearsonLatent ~~ machine_cor
  ')

fit <- sem(model, data = manifest_scores)
standardizedsolution(fit) %>% filter(lhs == "PearsonLatent", rhs ==  "machine_cor")

sim_results <- tibble()
library(lavaan)

for(i in 1:500) {
  scales <- manifest_scores %>% select(scale_a) %>% distinct() %>% sample_n(number_of_scales) %>% pull(scale_a)

  subset <- manifest_scores %>% filter(scale_a %in% scales, scale_b %in% scales)

  N <- 400
  subset <- subset %>% mutate(se = (1 - human_cor^2)/sqrt(N - 2))
  se2 <- mean(subset$se^2)

  r <- broom::tidy(cor.test(subset$human_cor, subset$machine_cor))
  (r$conf.high - r$conf.low)/2

  model <- paste0('
    # Latent variables
    PearsonLatent =~ 1*human_cor

    # Fixing error variances based on known standard errors
    human_cor ~~ ',se2,'*human_cor

    # Relationship between latent variables
    PearsonLatent ~~ machine_cor
  ')

  fit <- sem(model, data = subset)

  sim_results <- bind_rows(sim_results,
                           standardizedsolution(fit) %>% filter(lhs == "PearsonLatent", rhs ==  "machine_cor")
  )
}
sim_results %>% summarise(mean(est.std), sqrt(mean(se^2)), max(se))
```
